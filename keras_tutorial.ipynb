{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2fd3e30c-683a-4822-b66c-b44433498fb4"
    }
   },
   "source": [
    "# Introduction to Keras #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9aa90ae4-ccb4-4e11-ac66-694182876725"
    }
   },
   "source": [
    "## https://keras.io/ ## \n",
    "(Keras has great documentation, in fact, most of the examples below are taken in part of in full from the docs!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "105c3772-4173-4ef2-ace2-34ae4cb87861"
    }
   },
   "source": [
    "## Keras workflow for a sequential model -- MNIST toy example ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "1d0ff088-2f86-48bb-8818-f11e3d965029"
    }
   },
   "outputs": [],
   "source": [
    "import keras \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5f9c4818-f573-4be1-97c2-219b3f80f6a6"
    }
   },
   "source": [
    "A **Sequential** model class is a linear stack of layers. \n",
    "Each layer has it's own class. Some examples that you might encounter frequently are included in the import statements below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "9ac06fe8-8feb-429b-a227-6123d2121dbe"
    }
   },
   "outputs": [],
   "source": [
    "#import the Sequential model class. \n",
    "from keras.models import Sequential \n",
    "\n",
    "#Core layers \n",
    "from keras.layers.core import Dense, Activation,Dropout,Flatten\n",
    "\n",
    "#Convolution layers \n",
    "from keras.layers.convolutional import Conv1D, Conv2D \n",
    "\n",
    "#Pooling layers \n",
    "from keras.layers.pooling import MaxPooling1D, MaxPooling2D, AveragePooling1D, AveragePooling2D \n",
    "\n",
    "#Recurrent layers \n",
    "from keras.layers.recurrent import Recurrent, SimpleRNN, GRU, LSTM\n",
    "\n",
    "#Embedding layers \n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "#Merge layers \n",
    "from keras.layers.merge import Add, Multiply, Average, Maximum, Concatenate, Dot\n",
    "\n",
    "#Normalization layers \n",
    "from keras.layers.normalization import BatchNormalization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "7f772d73-2cea-4a33-8768-40f559e85e90"
    }
   },
   "outputs": [],
   "source": [
    "#the MNIST dataset is included with keras installation \n",
    "from keras.datasets import mnist \n",
    "(X_train,y_train),(X_test,y_test)=mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "95776b5b-aef2-4e7b-be13-5927378649e7"
    }
   },
   "outputs": [],
   "source": [
    "#we want to create a validation set to illustrate training with a validation dataset, so we \"hack\" this dataset by \n",
    "#splitting the test data into a test and validation dataset \n",
    "X_valid=X_test[0:int(X_test.shape[0]/2)]\n",
    "y_valid=y_test[0:int(y_test.shape[0]/2)]\n",
    "X_test=X_test[int(X_test.shape[0]/2)::]\n",
    "y_test=y_test[int(y_test.shape[0]/2)::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "d9a12e90-f2c0-4993-b91e-fa464821cabf"
    }
   },
   "outputs": [],
   "source": [
    "#Let's briefly examine our data  \n",
    "print(\"Training X:\"+str(X_train.shape))\n",
    "print(\"Training y:\"+str(y_train.shape))\n",
    "print(\"Valid X:\"+str(X_valid.shape))\n",
    "print(\"Valid y:\"+str(y_valid.shape))\n",
    "print(\"Test X:\"+str(X_test.shape))\n",
    "print(\"Test y:\"+str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "180488c5-949f-49f4-84bb-dd23e196ab08"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import imshow\n",
    "#You can visualize the digits that we classify \n",
    "digit_index=0\n",
    "imshow(X_train[digit_index])\n",
    "print(\"training label:\"+str(y_train[digit_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "3ac98894-da8c-414f-a91b-db87936a45ac"
    }
   },
   "outputs": [],
   "source": [
    "#plot our first test digit -- let's see if we can train a deep learning model to correctly predict this digit. \n",
    "imshow(X_test[digit_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "9cd05738-dbbe-4ca7-a050-8c632e5edc7e"
    }
   },
   "outputs": [],
   "source": [
    "#pre-process the input data \n",
    "from keras import backend as K \n",
    "from keras.utils import np_utils \n",
    "# input image dimensions                                                                                                                                                \n",
    "img_rows, img_cols = 28, 28\n",
    "#number of output classes\n",
    "nb_classes=10 \n",
    "\n",
    "\n",
    "#WARNING! order of dimensions differs for theano & tensorflow (that's why we check the backend and re-arrange the image \n",
    "#dimensions accordingly)\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    \n",
    "#this is done to normalize the data, as RGB values range in intensity from 0 to 255 \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_valid /= 255 \n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "print(X_valid.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices                                                                                                                        \n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_valid = np_utils.to_categorical(y_valid, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print(\"y_train shape:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "e8d472df-cfdd-4bee-8a02-63b55bf3b2cc"
    }
   },
   "outputs": [],
   "source": [
    "K.image_dim_ordering()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f640725b-e6d8-4472-9f44-e04ec053124e"
    }
   },
   "source": [
    "### We want to implement the following model architecture to train a CNN to recognize handwritten digits: \n",
    "````    \n",
    " Convolution2D\n",
    "     |\n",
    "     v\n",
    "   ReLU\n",
    "     |\n",
    "     v\n",
    "Convolution2D\n",
    "     |\n",
    "     v\n",
    "   ReLU\n",
    "     |\n",
    "     v\n",
    " MaxPool2D\n",
    "     |\n",
    "     v\n",
    "  Dropout \n",
    "     |\n",
    "     v\n",
    "  Flatten\n",
    "     |\n",
    "     v\n",
    "   Dense\n",
    "     |\n",
    "     v\n",
    "    ReLU\n",
    "     |\n",
    "     v\n",
    "  Dropout\n",
    "     |\n",
    "     v\n",
    "   Dense\n",
    "     |\n",
    "     v\n",
    "  Softmax\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0b20ac20-c1e1-4391-8798-fc45b4f6df01"
    }
   },
   "outputs": [],
   "source": [
    "#architecture hyperparameters \n",
    "# number of convolutional filters to use                                                                                                                                \n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling                                                                                                                                  \n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size                                                                                                                                               \n",
    "kernel_size = (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "e841541b-d37a-4189-a07c-0cba4314cae4"
    }
   },
   "outputs": [],
   "source": [
    "#model architecture \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]),\n",
    "                        padding='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "539bb367-a4a8-4db2-b7fd-b0e4d2e22537"
    }
   },
   "source": [
    "#### A quick note on \"padding\" parameter: \n",
    "\n",
    "* With padding=\"valid\" you get an output that is smaller than the input because the convolution is only computed where the input and the filter fully overlap.\n",
    "\n",
    "\n",
    "* With padding=\"same\" you get an output that is the \"same\" size as the input. That means that the filter has to go outside the bounds of the input by \"filter size / 2\" - the area outside of the input is normally padded with zeros.\n",
    "\n",
    "\n",
    "* Note that some libraries also support the padding=\"full\" where the filter goes even further outside the bounds of the input - up to \"filter size - 1\". This results in an output shape larger than the input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "647d0e86-4bb3-4b56-b7ca-cf9a269253e7"
    }
   },
   "outputs": [],
   "source": [
    "#compile the model \n",
    "\n",
    "#we can try several different optimizers \n",
    "#optimizer=\"adam\"\n",
    "#optimizer=\"adadelta\"\n",
    "#optimizer=\"adagrad\"\n",
    "optimizer=\"sgd\"\n",
    "\n",
    "#add momentum, alter learning rate: \n",
    "from keras.optimizers import SGD\n",
    "#optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "dd208054-ab67-4d88-b0e1-7a701ea9e65b"
    }
   },
   "outputs": [],
   "source": [
    "#from keras.utils import visualize_util\n",
    "#visualize_util.plot(model,to_file=\"model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "f793c1ab-d747-4e68-af57-3de591f6def7"
    }
   },
   "outputs": [],
   "source": [
    "#training\n",
    "batch_size=128\n",
    "nb_epoch=10\n",
    "history=model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch,verbose=1, validation_data=(X_valid, y_valid),shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "e92d92be-440f-4f4f-a219-27c6f1a8273b"
    }
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "7a3e7a2c-35a4-4d96-a632-82fa7ec953a9"
    }
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "ad9da494-f1f3-4d0b-87b2-97d88881b017"
    }
   },
   "outputs": [],
   "source": [
    "#training with fit generator \n",
    "import random \n",
    "\n",
    "#note: in a real \"use case\" x_matrix & y_matrix would likely be stored in an hdf5 file rather than loaded into memory. \n",
    "#check out http://www.h5py.org/\n",
    "def create_generator(x_matrix,y_matrix,samples_to_yield): \n",
    "    num_entries=x_matrix.shape[0]\n",
    "    upper_bound=num_entries-samples_to_yield\n",
    "    while 1: \n",
    "        batch_index=random.randint(0,upper_bound)\n",
    "        x=x_matrix[batch_index:batch_index+samples_to_yield]\n",
    "        y=y_matrix[batch_index:batch_index+samples_to_yield]\n",
    "        yield x,y\n",
    "\n",
    "\n",
    "#create the generator for training data \n",
    "train_generator=create_generator(X_train,y_train,batch_size)\n",
    "#create the generator for validation data \n",
    "valid_generator=create_generator(X_valid,y_valid,batch_size)\n",
    "\n",
    "samples_per_epoch=3000 \n",
    "nb_val_samples=1000\n",
    "\n",
    "nb_epoch=2 #for illustrative purposes, we'll use 2 epochs to save time \n",
    "history=model.fit_generator(train_generator, samples_per_epoch, nb_epoch, verbose=1, \n",
    "                    callbacks=[], validation_data=valid_generator, validation_steps=nb_val_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "58a6176c-b33d-4c85-9790-ff69ea2c9a94"
    }
   },
   "outputs": [],
   "source": [
    "#evaluate \n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "#evaluate with generator (for large dataset)\n",
    "evaluation_generator=create_generator(X_test,y_test,batch_size)\n",
    "nb_eval_samples=X_test.shape[0] \n",
    "score=model.evaluate_generator(evaluation_generator,nb_eval_samples)\n",
    "print(\"With evaluate_generator:\")\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "70bd33c6-077d-4c62-b583-5158ad3e7b4c"
    }
   },
   "outputs": [],
   "source": [
    "#predict classes\n",
    "class_predictions=model.predict_classes(X_test) \n",
    "\n",
    "#predict probabilities \n",
    "class_probabilities=model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "99e0e9b3-977b-46e1-a114-1459cc66cf85"
    }
   },
   "outputs": [],
   "source": [
    "#let's look at the prediction for our test digit of interest \n",
    "print(\"predicted class:\"+ str(class_predictions[digit_index]))\n",
    "print(\"predicted probability:\"+str([round(i,2) for i in class_probabilities[digit_index]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "764b027e-9c02-40b5-88c7-034ee2f0e113"
    }
   },
   "source": [
    "## Keras functional API ##\n",
    "The Keras functional API is the way to go for defining complex models, such as multi-output models, directed acyclic graphs, or models with shared layers.\n",
    "\n",
    "Use the functional API if you have: \n",
    "\n",
    "* multiple inputs & outputs \n",
    "* bypass layers\n",
    "* merge layers \n",
    "* basically any non-linear connection between layers \n",
    "\n",
    "\n",
    "There are a few key points to remember for the functional API: \n",
    "\n",
    "* A layer instance is callable (on a tensor), and it returns a tensor\n",
    "* Input tensor(s) and output tensor(s) can then be used to define a Model\n",
    "* Such a model can be trained just like Keras Sequential models.\n",
    "* All models are callable (just like layers). \n",
    "\n",
    "For example, let's look at a simple model that includes all layers required in the computation of output **b** given input **a**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "8f3be052-69e1-4b95-90bd-b58879a8fcd2"
    }
   },
   "outputs": [],
   "source": [
    "#The simplest possible example for the functional API \n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "a = Input(shape=(32,))\n",
    "b = Dense(32)(a)\n",
    "model = Model(inputs=a, outputs=b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fe336b7c-7d2e-4262-8427-e960ac68bd62"
    }
   },
   "source": [
    "Useful attributes of Model\n",
    "\n",
    "* `model.layers` is a flattened list of the layers comprising the model graph.\n",
    "* `model.inputs` is the list of input tensors.\n",
    "* `model.outputs` is the list of output tensors.\n",
    "\n",
    "It's very straightforward to extend this model formulation to multi-input and multi-output models: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "0bf44eb4-9f0f-401c-970c-e0ceff1dd14d"
    }
   },
   "outputs": [],
   "source": [
    "#example: multiple inputs and multiple outputs with the functional API \n",
    "a1 = Input(shape=(32,))\n",
    "a2 = Input(shape=(32,))\n",
    "\n",
    "b1 = Dense(32)(a1)\n",
    "b2 = Dense(32)(a2)\n",
    "\n",
    "model = Model(inputs=[a1, a2], outputs=[b1, b2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "36a3cbf6-1b15-478d-bfea-5f9a7cdcc5ed"
    }
   },
   "outputs": [],
   "source": [
    "#let's examine the attributes of the model \n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "bf2d9c31-f1eb-486c-978b-0d9ab65e18fb"
    }
   },
   "outputs": [],
   "source": [
    "model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "a9748b3a-71a1-46ed-a369-c175193e8269"
    }
   },
   "outputs": [],
   "source": [
    "model.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2a24687d-0d00-4e1a-98ea-1513ba27cd38"
    }
   },
   "source": [
    "## Example: Word embedding & training an LSTM with the functional API ## \n",
    " \n",
    "The functional API makes it easy to manipulate a large number of intertwined datastreams.\n",
    "\n",
    "Let's consider the following model. We seek to predict how many retweets and likes a news headline will receive on Twitter. The main input to the model will be the headline itself, as a sequence of words, but to spice things up, our model will also have an auxiliary input, receiving extra data such as the time of day when the headline was posted, etc. The model will also be supervised via two loss functions. \n",
    "\n",
    "Here's what our model looks like:\n",
    "![title](images/multi-input-multi-output-graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a25899d4-5b46-4b2e-b0be-beee3cc19a7c"
    }
   },
   "source": [
    "The main input will receive the headline, as a sequence of integers (each integer encodes a word). The integers will be between 1 and 10,000 (a vocabulary of 10,000 words) and the sequences will be 100 words long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "d934404a-046b-4c07-9912-5c7550d60900"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense,Merge\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "# headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# note that we can name any layer by passing it a \"name\" argument.\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "\n",
    "# this embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "\n",
    "# a LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(32)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "585e7344-e7fc-42f6-ae3e-cdb70f3181e1"
    }
   },
   "source": [
    "Here we insert the auxiliary loss, allowing the LSTM and Embedding layer to be trained smoothly even though the main loss will be much higher in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5d6318c8-34f8-49c1-b35f-4e65cc51fc4c"
    }
   },
   "outputs": [],
   "source": [
    "auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f3501821-5b61-4a9e-8977-4ca7628c228a"
    }
   },
   "source": [
    "At this point, we feed into the model our auxiliary input data by concatenating it with the LSTM output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "9af8785d-62b2-45a0-8084-18a8fd7178d1"
    }
   },
   "outputs": [],
   "source": [
    "auxiliary_input = Input(shape=(5,), name='aux_input')\n",
    "x = Concatenate()([lstm_out, auxiliary_input])\n",
    "\n",
    "# we stack a deep fully-connected network on top\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# and finally we add the main logistic regression layer\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e0c2ce08-3761-4376-b4b7-c805be534720"
    }
   },
   "source": [
    "This defines a model with two inputs and two outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "b9ea717a-bc57-4a73-90ac-1e66eceba1ef"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "da0aa40c-a37f-4a15-9964-cb11c9da2fad"
    }
   },
   "source": [
    "We compile the model and assign a weight of 0.2 to the auxiliary loss. To specify different loss_weights or loss for each different output, you can use a list or a dictionary. Here we pass a single loss as the loss argument, so the same loss will be used on all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "cfaf628a-5399-4067-a1e4-6fdf6647f064"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n",
    "              loss_weights=[1., 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3e07c460-a37a-4c19-b5ae-79f20806ab0e"
    }
   },
   "source": [
    "We can train the model by passing it lists of input arrays and target arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "bb36eb19-dfc8-4a63-b13b-e22cb7937be3"
    }
   },
   "outputs": [],
   "source": [
    "#model.fit([headline_data, additional_data], [labels, labels],\n",
    "#          nb_epoch=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e2798767-cd31-494d-a3f3-9bbb5ace434f"
    }
   },
   "source": [
    "Since our inputs and outputs are named (we passed them a \"name\" argument), We could also have compiled the model via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "e21134bb-3418-4624-ab48-8d47f0cf6b40"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},\n",
    "              loss_weights={'main_output': 1., 'aux_output': 0.2})\n",
    "\n",
    "# and trained it via:\n",
    "#model.fit({'main_input': headline_data, 'aux_input': additional_data},\n",
    "#          {'main_output': labels, 'aux_output': labels},\n",
    "#          nb_epoch=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4b29bc1a-329b-4927-aaa2-ff13d46b0fc7"
    }
   },
   "source": [
    "## Switching the keras backend (theano vs tensorflow) ## \n",
    "\n",
    "You can switch the backend by editing the file **~/.keras/keras.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "6cc13466-53c4-4dea-95ff-cab4a81a1a6b"
    }
   },
   "outputs": [],
   "source": [
    "! cat ~/.keras/keras.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3840651c-58ac-4217-be0f-60ee8a257f3a"
    }
   },
   "source": [
    "To use the tensorflow backend, just change \"theano\"  to \"tensorflow\". And you're done! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2a329ea9-8b2f-4afc-b9db-d44849104734"
    }
   },
   "source": [
    "## Getting fancy -- writing your own keras layers ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "cec3471e-f026-4f91-b2ac-6ccf79a4710a"
    }
   },
   "source": [
    "Here is the skeleton of a Keras layer. There are only three methods you need to implement:\n",
    "\n",
    "* **build(input_shape)**: this is where you will define your weights. Trainable weights should be added to the list self.trainable_weights. Other attributes of note are: self.non_trainable_weights (list) and self.updates (list of update tuples (tensor, new_tensor)). For an example of how to use non_trainable_weights and updates, see the code for the BatchNormalization layer.\n",
    "\n",
    "* **call(x)**: this is where the layer's logic lives. Unless you want your layer to support masking, you only have to care about the first argument passed to call: the input tensor.\n",
    "\n",
    "* **get_output_shape_for(input_shape)**: in case your layer modifies the shape of its input, you should specify here the shape transformation logic. This allows Keras to do automatic shape inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "8b4e06ff-5b7e-4f93-9c9c-50ccd4fe1085"
    }
   },
   "outputs": [],
   "source": [
    "#skeleton code for a keras layer\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import numpy as np\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[1]\n",
    "        initial_weight_value = np.random.random((input_dim, output_dim))\n",
    "        self.W = K.variable(initial_weight_value)\n",
    "        self.trainable_weights = [self.W]\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return K.dot(x, self.W)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
